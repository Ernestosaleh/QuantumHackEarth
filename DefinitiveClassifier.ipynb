{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DefinitiveClassifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLF0UKMmfVzi"
      },
      "source": [
        "!pip install qiskit\n",
        "!pip install qiskit-machine-learning\n",
        "!pip install qiskit-optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YId30LVtEzO5"
      },
      "source": [
        "# Clasificador Booleano de Números\n",
        "\n",
        "Este notebook se basa altamente en los tutoriales de Qiskit. Lo que se ha modificado drásticamente son los datos de entrada. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvV0UL6Ygrjj"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.nn import Linear, CrossEntropyLoss, MSELoss\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import LBFGS\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from qiskit  import Aer, QuantumCircuit\n",
        "from qiskit.utils import QuantumInstance\n",
        "from qiskit.opflow import AerPauliExpectation\n",
        "from qiskit.circuit import Parameter\n",
        "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
        "from qiskit_machine_learning.neural_networks import CircuitQNN, TwoLayerQNN\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier, VQC\n",
        "from qiskit.algorithms.optimizers import COBYLA, L_BFGS_B"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0gtnSJ7hQK8"
      },
      "source": [
        "# DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "lk8bRSmegZEf",
        "outputId": "8d2e9fd7-e894-4f60-d8cd-f2b4f9f27423"
      },
      "source": [
        "#Train Data\n",
        "#Si se tarda, es por que se está descargando a info de MNIST\n",
        "\n",
        "#Esto es MUY importante. Entre más pixeles mas lento el proceso\n",
        "side_pixels=3 #side_pixels^2 es el numero de qbits. \n",
        "\n",
        "# Concentrating on the first 100 samples\n",
        "n_samples = 12 #12 de cada número\n",
        "\n",
        "X_train = datasets.MNIST(root='./data', train=True, download=True,\n",
        "                         transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "# Leaving only labels 9 and 5 \n",
        "idx = np.append(np.where(X_train.targets == 5)[0][:n_samples], \n",
        "                np.where(X_train.targets == 9)[0][:n_samples])\n",
        "\n",
        "random.shuffle(idx)\n",
        "\n",
        "X_train.data = X_train.data[idx] #Data contiene información de las imagenes en matriz.\n",
        "\n",
        "\n",
        "\n",
        "#Redimensionamiento\n",
        "random_img=np.random.randint(0, high=len(X_train.data))\n",
        "sample=X_train.data\n",
        "sample=sample[None, :, :, :]\n",
        "out1 = F.interpolate(sample, size=(side_pixels, side_pixels))\n",
        "simg=ToPILImage()(sample[0][random_img])\n",
        "img = ToPILImage()(out1[0][random_img])\n",
        "\n",
        "display(simg.resize((40 * 5, 40 * 5), Image.NEAREST))\n",
        "display(img.resize((40 * 5, 40 * 5), Image.NEAREST))\n",
        "img.show()\n",
        "\n",
        "X_train.data=out1[0]\n",
        "Xtrain=torch.tensor([list(torch.flatten(data)) for data in X_train.data])/255\n",
        "print(len(Xtrain))\n",
        "\n",
        "X_train.targets = X_train.targets[idx] #Targets son los labels\n",
        "Map=lambda i: 1 if i==5 else 0 #Long function\n",
        "Ytrain = torch.tensor([Map(x) for x in X_train.targets])\n",
        "\n",
        "#print(X_train.data[0]) #Veelo por ti mismo\n",
        "\n",
        "print(len(Ytrain))\n",
        "\n",
        "#-----------------------------------\n",
        "\n",
        "#Test Data\n",
        "\n",
        "n_samples = 100\n",
        "\n",
        "#Now train=False, this are images for testing\n",
        "X_test = datasets.MNIST(root='./data', train=False, download=True,\n",
        "                        transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "idx = np.append(np.where(X_test.targets == 5)[0][:n_samples], \n",
        "                np.where(X_test.targets == 9)[0][:n_samples])\n",
        "random.shuffle(idx)\n",
        "\n",
        "X_test.data = X_test.data[idx]\n",
        "\n",
        "random_img=np.random.randint(0, high=len(X_test.data))\n",
        "sample=X_test.data\n",
        "sample=sample[None, :, :, :]\n",
        "out1 = F.interpolate(sample, size=(side_pixels, side_pixels))\n",
        "\n",
        "X_test.data=out1[0]\n",
        "print(len(X_test.data))\n",
        "\n",
        "Xtest=torch.tensor([list(torch.flatten(data)) for data in X_test.data])/255\n",
        "print(len(Xtest))\n",
        "\n",
        "X_test.targets = X_test.targets[idx]\n",
        "print(X_test.targets)\n",
        "Ytest = torch.tensor([Map(x) for x in X_test.targets])\n",
        "\n",
        "\n",
        "n=4\n",
        "simg=ToPILImage()(sample[0][n])\n",
        "\n",
        "print(\"test images comprobation:\")\n",
        "display(simg.resize((40 * 5, 40 * 5), Image.NEAREST))\n",
        "print(Ytest[n])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAACVUlEQVR4nO2cO2tUURRGJxJQkGAQLHxUqRRCKv0J1mJhExtLCTZ5WdilsA02IpI+VX5CmqQRLBRflSCkEZQgMWVCxOLbKQ7I6MzsyXzZrtUs7uXmHlY2nAm5M9PpAAAAAAAAAAAAAAAAAAAAAMCIGRvq3c9Ik9I1aba95pF0XtqXHksve17q9EOIG4S4USZkPPl+F6Q70m1p9s/Xip/SVym2382eFy4zEULcIMSNMiHZ2++S9KTLJXvS5zicl14NuHCZiRDiBiFulAnJ2n7XwvebswfSsvRJ2pU+JK0clJkIIW4Q4kaZkKz//b4NzzRnv0lXkhbpRpmJEOIGIW4Q4kbWn/Fvwu3ryIuku/8DZSZCiBuEuFEmJGv7PX7o90A6as+eAGUmQogbhLhRJiT7GWIQ2++gDwZ7oMxECHGDEDcIcYMQNwhxgxA3CHGDEDcIcaNMSNZbOC6F30sXpRvSl6RFulFmIoS4QYgbZUKyPz29I8UHpb9LP5pL1qXncbiXs3CZiRDiBiFuEOJG9uvIhnT371duhVfaw34pMxFC3CDEjTIh2dtv/GIWpI/STemeNN3+xDNpMWfh0w8hbhDiRpmQ4X4HXctlaVuairPvpFvSUb83LzMRQtwgxI0yISe5/QYPpdU4PCudkw77vWuZiRDiBiFulAkZwfYbxFcida5LbL8BIW4Q4kaZkCF9fK8b8ZVIE7l3LTMRQtwgxI0yISPYfuekq3EYj+d+DXjXMhMhxA1C3CDEjRG8jrxuD59KfT88DMpMhBA3CHGjTAgAAAAAwP/Db0JLMop9N9XVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=200x200 at 0x7F12835BC790>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAAAiklEQVR4nO3PQQ2AQAADwYIx/LtCxD3YkBkBTXcDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANKurw9s257zift8okFIjZAaITVCaoTUCKkRUiOkRkiNkBohNUJqhNQIqRFSI6RGSI2QGiE1QmqE1AipEVIjpEZIjZAaITVCaoTUCKkRUiOk5jchLzRZAMVcg5yNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=200x200 at 0x7F127CE0E450>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "24\n",
            "24\n",
            "200\n",
            "200\n",
            "tensor([9, 5, 5, 9, 9, 5, 5, 5, 9, 9, 5, 9, 9, 5, 5, 9, 5, 9, 9, 9, 9, 9, 9, 9,\n",
            "        9, 9, 9, 9, 9, 5, 9, 9, 9, 9, 5, 9, 5, 9, 9, 9, 9, 9, 5, 9, 9, 9, 5, 5,\n",
            "        5, 5, 9, 5, 9, 9, 5, 5, 5, 9, 5, 5, 5, 5, 5, 9, 9, 5, 5, 5, 5, 9, 5, 9,\n",
            "        5, 9, 5, 5, 5, 9, 5, 5, 9, 9, 5, 9, 5, 9, 9, 5, 5, 5, 9, 5, 5, 9, 9, 9,\n",
            "        5, 5, 9, 9, 9, 5, 5, 9, 5, 9, 5, 5, 5, 9, 9, 5, 5, 5, 5, 5, 5, 5, 5, 9,\n",
            "        5, 9, 9, 5, 5, 5, 9, 5, 5, 5, 9, 5, 9, 9, 5, 9, 9, 9, 5, 5, 9, 9, 9, 9,\n",
            "        9, 5, 9, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 9, 9, 9, 5, 9, 9, 5, 9, 5, 9, 9,\n",
            "        9, 5, 9, 9, 9, 9, 5, 9, 9, 9, 5, 5, 5, 9, 5, 5, 9, 5, 9, 5, 5, 9, 5, 9,\n",
            "        5, 5, 5, 9, 9, 5, 9, 5])\n",
            "test images comprobation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAACk0lEQVR4nO2dPWgUQRiGTxFsBFOl0EIwtZZBEFKJpWgRVLA0IIKFllrbaGthl0qsRRttrGxMqVgIFgrBVGlVhMTi/VJsGJZlZry8fj5P87KzPzPPfTC32Zu7zGYAAAAAAAAAAAAAAAAAAAAAcMAc6ny9RcUNxaVBJx8UjxTf+nZ8uO/lDg5E3EDEjTQizdPvccXt2LypOFXqZFfxVfEidt5rHYFIUxFE3EDEjTQizdPvY8XdCZ3sDhp/R75T3Fe8rx1Hmoog4gYibqQRqZ9+TyreKk4Xj9lQvFacU1woHvpKcbl2OGkqgogbiLiRRuRI9ZkPFEuKvTvbn4rrijeKX4pVRXn6XaoeiEhTEUTcQMQNRNyofx9ZUcQrsROt8VDl5ciJ5b8cnlYPZDCOfx9E3EDEjTQi9dNv3LjvDLb2PageO3FS63TSVAQRNxBxI41I/fT7o9i6rFgcNMb6jtWxy21UD0SkqQgibiDiRhqR+s8Q46nzZ8XozWtxCcce64q16oGINBVBxA1E3Egj0ryC7pni6oROytPvWcWnxnGkqQgibiDiRhqR+ocPwR3FVmxeU2wPjjmhWGjta4w0FUHEDUTcSCPS+9vTsax5c9D4RHGreMYVxdhaiSmkqQgibiDiBiJuNN/G72Oz1Fj+uDF4rjjW2HGaiiDiBiJupBHpPf0W+T62c3ts53TSVAQRNxBxI43IXKbf8nfEgy99+khTEUTcQMSNNCJzmX7PKMoPzFf69JGmIoi4gYgbaUTmMv3GTy+f/5t9pKkIIm4g4gYibiDiBiJuIOLGXO5+46foyivo1vv0kaYiiLiBiBuIuNF7JXaRo4r4lykXFR9j50PF1qyNNBVBxA1E3EgjAgAAAADw//AHbVo6yIzym00AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=200x200 at 0x7F127CE30990>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj2BTkWs4XoN"
      },
      "source": [
        "# Quantum Circuit Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs_46dy_TPWm",
        "outputId": "a147ab40-2d29-46ec-dc89-d2a8ac028a1c"
      },
      "source": [
        "quantum_instance = QuantumInstance(Aer.get_backend('aer_simulator'), shots=1024)\n",
        "\n",
        "num_inputs=int(side_pixels**2)\n",
        "feature_map = ZZFeatureMap(num_inputs)\n",
        "ansatz = RealAmplitudes(num_inputs, entanglement='linear', reps=1)\n",
        "\n",
        "# Define quantum circuit of num_qubits = input dim\n",
        "# Append feature map and ansatz\n",
        "qc = QuantumCircuit(num_inputs)\n",
        "qc.append(feature_map, range(num_inputs))\n",
        "qc.append(ansatz, range(num_inputs))\n",
        "\n",
        "\n",
        "# Define CircuitQNN and initial setup\n",
        "parity = lambda x: '{:b}'.format(x).count('1') % 2 # optional interpret function\n",
        "output_shape = 2  # parity = 0, 1\n",
        "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters,\n",
        "                  interpret=parity, output_shape=output_shape, quantum_instance=quantum_instance)\n",
        "\n",
        "# Set up PyTorch module\n",
        "# Reminder: If we don't explicitly declare the initial weights\n",
        "# they are chosen uniformly at random from [-1, 1].\n",
        "np.random.seed(9)\n",
        "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
        "print(\"Initial weights: \", initial_weights)\n",
        "model2 = TorchConnector(qnn2, initial_weights)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights:  [-0.09792517  0.00037492 -0.00084534 -0.07323409 -0.07157778 -0.05628826\n",
            " -0.01629836 -0.05037977 -0.08318807 -0.03090027 -0.06664473  0.07571182\n",
            "  0.09019281 -0.09225032  0.03982148  0.01455196  0.07960142  0.03337979]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3XxGVjsTsNW",
        "outputId": "57714eae-1248-427a-b5a3-792d24e71505"
      },
      "source": [
        "\n",
        "# Define model, optimizer, and loss\n",
        "optimizer = LBFGS(model2.parameters())\n",
        "f_loss = CrossEntropyLoss() # Our output will be in the [0,1] range\n",
        "\n",
        "# Start training\n",
        "model2.train()\n",
        "\n",
        "# Define LBFGS closure method (explained in previous section)\n",
        "def closure():\n",
        "    optimizer.zero_grad(set_to_none=True)                  # Initialize gradient\n",
        "    loss = f_loss(model2(Xtrain), Ytrain)                        # Calculate loss\n",
        "    loss.backward()                                        # Backward pass\n",
        "\n",
        "    print(loss.item())                                     # Print loss\n",
        "    return loss\n",
        "\n",
        "# Run optimizer (LBFGS requires closure)\n",
        "optimizer.step(closure);"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6852800846099854\n",
            "0.6880813241004944\n",
            "0.6832675933837891\n",
            "0.6911059021949768\n",
            "0.6946389079093933\n",
            "0.6887882351875305\n",
            "0.6781919002532959\n",
            "0.7043651938438416\n",
            "0.6933479905128479\n",
            "0.6784207820892334\n",
            "0.6956479549407959\n",
            "0.6901163458824158\n",
            "0.6940956115722656\n",
            "0.7036826610565186\n",
            "0.7005148530006409\n",
            "0.693030595779419\n",
            "0.6913158893585205\n",
            "0.6902520656585693\n",
            "0.693662703037262\n",
            "0.6910346150398254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76nWkGXsmyC3"
      },
      "source": [
        "# Resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJVDljvWYLug"
      },
      "source": [
        "#Test images calssification\n",
        "#Esto se comprobará en la siguientes celdas, donde se volvio a ejecutar la \n",
        "#celda que generá test data para así proveer diferentes resultados\n",
        "y_predict = []\n",
        "for x in Xtest:\n",
        "    output = model2(x)\n",
        "    y_predict += [np.argmax(output.detach().numpy())]\n",
        "    #print(\"Valor de la etiqueta: {}\".format(Ytest[i]))\n",
        "    #print(\"Valor de la predicción: {}\".format(y_predict[i]))"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M0lGkV8e3iN",
        "outputId": "a73b3c7c-b15d-473a-e3e9-bed458bf2a38"
      },
      "source": [
        "#Para datos generados al azar: Sample\n",
        "i=0\n",
        "sum=0\n",
        "for prediction in y_predict:\n",
        "  if y_predict[i]==Ytest[0]:\n",
        "    sum+=1\n",
        "  i+=1\n",
        "accur=sum/len(Ytest)\n",
        "\n",
        "print('Accuracy:', accur)\n",
        "print(y_predict)\n",
        "print(Ytest)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.84\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0]\n",
            "tensor([0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
            "        1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
            "        1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKqby3F3j3nm",
        "outputId": "43f69d50-5cc9-44b0-c689-efd2950fc9f8"
      },
      "source": [
        "#Para datos generados al azar: Sample 2 #aqui use 200 samples\n",
        "i=0\n",
        "sum=0\n",
        "for prediction in y_predict:\n",
        "  if y_predict[i]==Ytest[0]:\n",
        "    sum+=1\n",
        "  i+=1\n",
        "accur=sum/len(Ytest)\n",
        "\n",
        "print('Accuracy:', accur)\n",
        "print(y_predict)\n",
        "print(Ytest)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.86\n",
            "[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0]\n",
            "tensor([0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
            "        0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
            "        0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
            "        0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
            "        0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
            "        1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
            "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
            "        0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
            "        1, 1, 0, 0, 1, 1, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUn2dxsnkX-m",
        "outputId": "6b3e6d24-fdbd-40c4-cabe-e98d29e1b966"
      },
      "source": [
        "#Para datos generados al azar: Sample 2\n",
        "i=0\n",
        "sum=0\n",
        "for prediction in y_predict:\n",
        "  if y_predict[i]==Ytest[0]:\n",
        "    sum+=1\n",
        "  i+=1\n",
        "accur=sum/len(Ytest)\n",
        "\n",
        "print('Accuracy:', accur)\n",
        "print(y_predict)\n",
        "print(Ytest)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.82\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
            "        1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
            "        0, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsUSxouJN1iW"
      },
      "source": [
        "# Análisis de Resultados\n",
        "Se observa en el notebook anterior que el algoritmo de optimización no fue satisfactorio. Dejando la función de costo Más Elevada\n",
        "\n",
        "La precisión resulta ser convenientemente baja o alta en la mayoría de las pruebas. Como las categorías son booleanas, muchas veces podemos invertir los resultados\n",
        "\n",
        "Para obtener una precisión más justa:\n",
        "\n",
        "Este feature no se ha desarrollado más debido a la falta de tiempo con la que nos quedamos.\n",
        "\n",
        "This is a poor analysis, so better supervision should be done.\n",
        "\n",
        "Number of tests could also be upgraded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-eX0GAx5uvU"
      },
      "source": [
        "# Referencias:\n",
        "1. Documentación de Qiskit\n",
        "\n",
        "- https://qiskit.org/documentation/machine-learning/tutorials/05_torch_connector.html\n",
        "\n",
        "- https://qiskit.org/documentation/machine-learning/tutorials/02_neural_network_classifier_and_regressor.html\n",
        "\n",
        "- https://qiskit.org/documentation/machine-learning/tutorials/01_neural_networks.html\n",
        "\n",
        "- https://sooluthomas.github.io/testTranslation/aqua/feature_maps.html\n",
        "\n",
        "2. Proyecto análogo hecho con Q Tensor Flow de Google\n",
        "\n",
        "- https://thesai.org/Downloads/Volume11No10/Paper_40-Handwritten_Numeric_Image_Classification.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohPv49_j556p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}